---
subcategory: "Batch"
layout: "aws"
page_title: "AWS: aws_batch_job_definition"
description: |-
  Provides a Batch Job Definition resource.
---

# Resource: aws_batch_job_definition

Provides a Batch Job Definition resource.

## Example Usage

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.aws as aws
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        aws.batch_job_definition.BatchJobDefinition(self, "test",
            container_properties=cdktf.Fn.jsonencode({
                "command": ["ls", "-la"],
                "environment": [{
                    "name": "VARNAME",
                    "value": "VARVAL"
                }
                ],
                "image": "busybox",
                "mount_points": [{
                    "container_path": "/tmp",
                    "read_only": False,
                    "source_volume": "tmp"
                }
                ],
                "resource_requirements": [{
                    "type": "VCPU",
                    "value": "0.25"
                }, {
                    "type": "MEMORY",
                    "value": "512"
                }
                ],
                "ulimits": [{
                    "hard_limit": 1024,
                    "name": "nofile",
                    "soft_limit": 1024
                }
                ],
                "volumes": [{
                    "host": {
                        "source_path": "/tmp"
                    },
                    "name": "tmp"
                }
                ]
            }),
            name="tf_test_batch_job_definition",
            type="container"
        )
```

### Fargate Platform Capability

```python
import constructs as constructs
import cdktf as cdktf
# Provider bindings are generated by running cdktf get.
# See https://cdk.tf/provider-generation for more details.
import ...gen.providers.aws as aws
class MyConvertedCode(cdktf.TerraformStack):
    def __init__(self, scope, name):
        super().__init__(scope, name)
        data_aws_iam_policy_document_assume_role_policy =
        aws.data_aws_iam_policy_document.DataAwsIamPolicyDocument(self, "assume_role_policy",
            statement=[DataAwsIamPolicyDocumentStatement(
                actions=["sts:AssumeRole"],
                principals=[DataAwsIamPolicyDocumentStatementPrincipals(
                    identifiers=["ecs-tasks.amazonaws.com"],
                    type="Service"
                )
                ]
            )
            ]
        )
        aws_iam_role_ecs_task_execution_role = aws.iam_role.IamRole(self, "ecs_task_execution_role",
            assume_role_policy=cdktf.Token.as_string(data_aws_iam_policy_document_assume_role_policy.json),
            name="tf_test_batch_exec_role"
        )
        aws.iam_role_policy_attachment.IamRolePolicyAttachment(self, "ecs_task_execution_role_policy",
            policy_arn="arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy",
            role=cdktf.Token.as_string(aws_iam_role_ecs_task_execution_role.name)
        )
        aws.batch_job_definition.BatchJobDefinition(self, "test",
            container_properties=cdktf.Fn.jsonencode({
                "command": ["echo", "test"],
                "execution_role_arn": aws_iam_role_ecs_task_execution_role.arn,
                "fargate_platform_configuration": {
                    "platform_version": "LATEST"
                },
                "image": "busybox",
                "job_role_arn": "arn:aws:iam::123456789012:role/AWSBatchS3ReadOnly",
                "resource_requirements": [{
                    "type": "VCPU",
                    "value": "0.25"
                }, {
                    "type": "MEMORY",
                    "value": "512"
                }
                ]
            }),
            name="tf_test_batch_job_definition",
            platform_capabilities=["FARGATE"],
            type="container"
        )
```

## Argument Reference

The following arguments are required:

* `name` - (Required) Specifies the name of the job definition.
* `type` - (Required) The type of job definition. Must be `container`.

The following arguments are optional:

* `container_properties` - (Optional) A valid [container properties](http://docs.aws.amazon.com/batch/latest/APIReference/API_RegisterJobDefinition.html)
    provided as a single valid JSON document. This parameter is required if the `type` parameter is `container`.
* `parameters` - (Optional) Specifies the parameter substitution placeholders to set in the job definition.
* `platform_capabilities` - (Optional) The platform capabilities required by the job definition. If no value is specified, it defaults to `EC2`. To run the job on Fargate resources, specify `FARGATE`.
* `propagate_tags` - (Optional) Specifies whether to propagate the tags from the job definition to the corresponding Amazon ECS task. Default is `false`.
* `retry_strategy` - (Optional) Specifies the retry strategy to use for failed jobs that are submitted with this job definition.
    Maximum number of `retry_strategy` is `1`.  Defined below.
* `tags` - (Optional) Key-value map of resource tags. If configured with a provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block) present, tags with matching keys will overwrite those defined at the provider-level.
* `timeout` - (Optional) Specifies the timeout for jobs so that if a job runs longer, AWS Batch terminates the job. Maximum number of `timeout` is `1`. Defined below.

### retry_strategy

* `attempts` - (Optional) The number of times to move a job to the `RUNNABLE` status. You may specify between `1` and `10` attempts.
* `evaluate_on_exit` - (Optional) The [evaluate on exit](#evaluate_on_exit) conditions under which the job should be retried or failed. If this parameter is specified, then the `attempts` parameter must also be specified. You may specify up to 5 configuration blocks.

#### evaluate_on_exit

* `action` - (Required) Specifies the action to take if all of the specified conditions are met. The values are not case sensitive. Valid values: `RETRY`, `EXIT`.
* `on_exit_code` - (Optional) A glob pattern to match against the decimal representation of the exit code returned for a job.
* `on_reason` - (Optional) A glob pattern to match against the reason returned for a job.
* `on_status_reason` - (Optional) A glob pattern to match against the status reason returned for a job.
  
### timeout

* `attempt_duration_seconds` - (Optional) The time duration in seconds after which AWS Batch terminates your jobs if they have not finished. The minimum value for the timeout is `60` seconds.

## Attributes Reference

In addition to all arguments above, the following attributes are exported:

* `arn` - The Amazon Resource Name of the job definition.
* `revision` - The revision of the job definition.
* `tags_all` - A map of tags assigned to the resource, including those inherited from the provider [`default_tags` configuration block](https://registry.terraform.io/providers/hashicorp/aws/latest/docs#default_tags-configuration-block).

## Import

Batch Job Definition can be imported using the `arn`, e.g.,

```
$ terraform import aws_batch_job_definition.test arn:aws:batch:us-east-1:123456789012:job-definition/sample
```

<!-- cache-key: cdktf-0.17.0-pre.15 input-d96f154675b94fe82b7a200993cff487a4700185339565a3cda16d891fc836e3 -->